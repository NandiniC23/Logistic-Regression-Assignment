{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "-  Logistic Regression\n",
        "\n",
        "Logistic Regression is a statistical method used for classification problems, where the target variable is categorical. It's used to predict the probability of an event occurring based on a set of independent variables.\n",
        "\n",
        "Key Differences\n",
        "\n",
        "| Aspect              | Linear Regression               | Logistic Regression                 |\n",
        "| ------------------- | ------------------------------- | ----------------------------------- |\n",
        "| **Type of Problem** | Regression (continuous output)  | Classification (categorical output) |\n",
        "| **Output Range**    | Any real value (−∞ to +∞)       | Probability between 0 and 1         |\n",
        "| **Function Used**   | Linear function                 | Sigmoid (logistic) function         |\n",
        "| **Error Metric**    | Mean Squared Error (MSE), RMSE  | Log Loss (Cross-Entropy Loss)       |\n",
        "| **Goal**            | Fit best line to predict values | Find probability and classify data  |\n",
        "\n",
        "#**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n",
        "-  Sigmoid Function in Logistic Regression\n",
        "\n",
        "The sigmoid function, also known as the logistic function, plays a crucial role in Logistic Regression. It's used to model the probability of the target variable being in a specific class (e.g., 1 or 0).\n",
        "\n",
        "Mathematical Representation\n",
        "The sigmoid function is represented mathematically as:\n",
        "\n",
        "σ(z) = 1 / (1 + e^(-z))\n",
        "\n",
        "Where:\n",
        "\n",
        "- σ(z): Sigmoid function\n",
        "- e: Base of the natural logarithm\n",
        "- z: Linear combination of the independent variables and their coefficients\n",
        "\n",
        "Role in Logistic Regression\n",
        "The sigmoid function serves several purposes in Logistic Regression:\n",
        "\n",
        "1. Mapping to Probability Space: The sigmoid function maps any real number to a value between 0 and 1, making it suitable for modeling probabilities.\n",
        "2. Non-Linearity: The sigmoid function introduces non-linearity into the model, allowing it to learn complex relationships between the independent variables and the target variable.\n",
        "3. Binary Classification: The sigmoid function is particularly useful for binary classification problems, where the target variable has two classes (e.g., 0 and 1).\n",
        "\n",
        "#**Question 3: What is Regularization in Logistic Regression and why is it needed?**\n",
        "-  Regularization in Logistic Regression\n",
        "\n",
        "Regularization is a technique used in Logistic Regression to prevent overfitting by adding a penalty term to the loss function. Overfitting occurs when a model is too complex and fits the training data too well, resulting in poor performance on unseen data.\n",
        "\n",
        "Why is Regularization Needed?\n",
        "Regularization is needed in Logistic Regression for several reasons:\n",
        "\n",
        "1. Preventing Overfitting: Regularization helps prevent overfitting by reducing the complexity of the model.\n",
        "2. Improving Generalization: Regularization improves the model's ability to generalize to new, unseen data.\n",
        "3. Reducing Model Variance: Regularization reduces the variance of the model, making it more stable and reliable.\n",
        "\n",
        "Types of Regularization\n",
        "There are two common types of regularization used in Logistic Regression:\n",
        "\n",
        "1. L1 Regularization (Lasso): L1 regularization adds a penalty term proportional to the absolute value of the model coefficients.\n",
        "2. L2 Regularization (Ridge): L2 regularization adds a penalty term proportional to the square of the model coefficients.\n",
        "\n",
        "#**Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n",
        "-  Common Evaluation Metrics for Classification Models\n",
        "\n",
        "When evaluating classification models, several metrics can be used to assess their performance. Here are some common ones:\n",
        "\n",
        "1. Accuracy: Accuracy measures the proportion of correctly classified instances out of all instances in the dataset.\n",
        "2. Precision: Precision measures the proportion of true positives (correctly predicted instances) among all positive predictions made by the model.\n",
        "3. Recall: Recall, also known as sensitivity, measures the proportion of true positives among all actual positive instances in the dataset.\n",
        "4. F1 Score: The F1 score is the harmonic mean of precision and recall, providing a balanced measure of both.\n",
        "5. Area Under the ROC Curve (AUC-ROC): AUC-ROC measures the model's ability to distinguish between positive and negative classes, with higher values indicating better performance.\n",
        "\n",
        "Importance of Evaluation Metrics\n",
        "These evaluation metrics are important for several reasons:\n",
        "\n",
        "- Assessing Model Performance: Evaluation metrics provide a quantitative measure of a model's performance, allowing you to compare different models and identify areas for improvement.\n",
        "- Identifying Class Imbalance Issues: Metrics like precision, recall, and F1 score can help identify class imbalance issues, where one class has a significantly larger number of instances than others.\n",
        "- Optimizing Model Parameters: Evaluation metrics can be used to optimize model parameters and hyperparameters, ensuring the best possible performance.\n",
        "- Comparing Models: Evaluation metrics enable comparison between different models, helping you choose the best model for your specific problem.\n"
      ],
      "metadata": {
        "id": "WSc2iMqWuHwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.**"
      ],
      "metadata": {
        "id": "AU1_ZGy2xCLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset as an example)\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(\"First 5 rows of dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxoAZ75_xM7Z",
        "outputId": "7603605e-f7dc-4b1e-f8df-3efa1e0de7ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.**\n"
      ],
      "metadata": {
        "id": "1_Jq0IdExRvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset as example)\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with L2 regularization\n",
        "# C is inverse of regularization strength (smaller C = stronger regularization)\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500, multi_class='auto')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print coefficients and accuracy\n",
        "print(\"Model Coefficients (per class):\\n\", model.coef_)\n",
        "print(\"\\nIntercepts (per class):\\n\", model.intercept_)\n",
        "print(\"\\nModel Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d63HZEU0E5n",
        "outputId": "89f09638-7d3e-4ff6-ce96-6402788c2ab5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients (per class):\n",
            " [[-0.40538546  0.86892246 -2.2778749  -0.95680114]\n",
            " [ 0.46642685 -0.37487888 -0.18745257 -0.72127133]\n",
            " [-0.06104139 -0.49404358  2.46532746  1.67807247]]\n",
            "\n",
            "Intercepts (per class):\n",
            " [  8.86383271   2.20981479 -11.0736475 ]\n",
            "\n",
            "Model Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.**"
      ],
      "metadata": {
        "id": "_XB-KVd80efG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize Logistic Regression with One-vs-Rest\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=500)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYoE9SgD0lbV",
        "outputId": "9d956e0e-bea9-4565-8912-7c100d636804"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      0.85      0.92        13\n",
            "   virginica       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.**"
      ],
      "metadata": {
        "id": "wOjydIHT0w97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Define Logistic Regression model\n",
        "log_reg = LogisticRegression(solver='liblinear', max_iter=500)\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],          # Regularization strength\n",
        "    'penalty': ['l1', 'l2']                # L1 = Lasso, L2 = Ridge\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,               # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and validation accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30C_1DUF1Hku",
        "outputId": "2738ab8f-c965-411c-c2bc-3e8fb72c5529"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Best Cross-Validation Accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.**"
      ],
      "metadata": {
        "id": "Vwcp1YMN05AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset)\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# ---------------- Without Scaling ----------------\n",
        "model_no_scaling = LogisticRegression(max_iter=500)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# ---------------- With Standard Scaling ----------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_with_scaling = LogisticRegression(max_iter=500)\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# ---------------- Results ----------------\n",
        "print(\"Accuracy without Scaling:\", accuracy_no_scaling)\n",
        "print(\"Accuracy with Scaling   :\", accuracy_with_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG_gYQbi1eHU",
        "outputId": "78cbc17b-b351-4382-c4ad-5afc48f78038"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 1.0\n",
            "Accuracy with Scaling   : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n",
        "  \n",
        "1. Data Handling\n",
        "\n",
        "Exploration:\n",
        "\n",
        "Check missing values, outliers, and data distribution.\n",
        "\n",
        "Look for data leakage (e.g., features that directly reveal response).\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "Categorical features → one-hot encoding.\n",
        "\n",
        "Date/time features → extract month/weekday/recency (how recently a customer purchased).\n",
        "\n",
        "Customer behavior features (purchase frequency, last purchase amount, etc.).\n",
        "\n",
        " 2. Feature Scaling\n",
        "\n",
        "Logistic Regression with regularization (L1/L2) is sensitive to feature scale.\n",
        "\n",
        "Apply StandardScaler (zero mean, unit variance) or MinMaxScaler to numerical variables.\n",
        "\n",
        "Apply scaling after train/test split to avoid data leakage.\n",
        "\n",
        " 3. Handling Class Imbalance (5% responders)\n",
        "\n",
        "Imbalanced data is the biggest challenge here. Options:\n",
        "\n",
        "Resampling Methods\n",
        "\n",
        "Oversampling minority class (e.g., SMOTE, ADASYN).\n",
        "\n",
        "Undersampling majority class (but risk losing info).\n",
        "\n",
        "Class Weights\n",
        "\n",
        "In scikit-learn: LogisticRegression(class_weight='balanced')\n",
        "\n",
        "This adjusts weights so minority class has higher importance.\n",
        "\n",
        "Hybrid Approaches\n",
        "\n",
        "Use moderate oversampling + class weights.\n",
        "\n",
        " 4. Model Training with Hyperparameter Tuning\n",
        "\n",
        "Use GridSearchCV or RandomizedSearchCV for:\n",
        "\n",
        "C → regularization strength.\n",
        "\n",
        "penalty → L1 (Lasso) or L2 (Ridge).\n",
        "\n",
        "class_weight → balanced vs. custom weights.\n",
        "\n",
        "Example grid:\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "\n",
        "Cross-validation should use StratifiedKFold to maintain class balance.\n",
        "\n",
        " 5. Evaluation Metrics (beyond accuracy)\n",
        "\n",
        "Accuracy is misleading (95% accuracy if predicting “no” always!).\n",
        "\n",
        "Use metrics focused on minority class:\n",
        "\n",
        "Precision, Recall, F1-score\n",
        "\n",
        "ROC-AUC (probability-based measure)\n",
        "\n",
        "PR-AUC (Precision-Recall AUC) → especially important in high imbalance.\n",
        "\n",
        "Business Metric: Focus on Recall (catch as many responders as possible) OR Precision (don’t waste marketing cost) depending on company strategy.\n",
        "\n",
        " 6. Threshold Tuning\n",
        "\n",
        "Default threshold = 0.5 may not be optimal.\n",
        "\n",
        "Adjust threshold using ROC curve or Precision-Recall curve.\n",
        "\n",
        "For example:\n",
        "\n",
        "If marketing budget is high → lower threshold → catch more responders (maximize recall).\n",
        "\n",
        "If budget is limited → higher threshold → focus on most likely responders (maximize precision).\n",
        "\n",
        " 7. Deployment & Monitoring\n",
        "\n",
        "Deploy model in marketing workflow.\n",
        "\n",
        "Monitor:\n",
        "\n",
        "Response rate over time.\n",
        "\n",
        "Model drift (customer behavior changes).\n",
        "\n",
        "Re-train periodically with fresh data.\n",
        "\n",
        "**Summary Approach:**\n",
        "\n",
        "Preprocess features + scale data.\n",
        "\n",
        "Handle imbalance (SMOTE / class_weight).\n",
        "\n",
        "Train Logistic Regression with hyperparameter tuning.\n",
        "\n",
        "Evaluate using Precision, Recall, F1, ROC-AUC, PR-AUC (not just accuracy).\n",
        "\n",
        "Adjust threshold based on business cost/benefit trade-off.\n",
        "\n",
        "Deploy and monitor performance."
      ],
      "metadata": {
        "id": "nuoaTBLW1T0B"
      }
    }
  ]
}